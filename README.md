# AI Business Assistant - Full Stack Application

A powerful AI-powered research and brainstorming engine with real-time chat interface, featuring WebSocket communication, memory management, and integration with CRM/PMS systems.

## ğŸš€ Features

- **Real-time Chat Interface**: WebSocket-based communication for instant responses
- **AI-Powered Research**: Comprehensive web research with source citations
- **Memory Management**: Short-term and long-term memory using Mem0
- **Streaming Responses**: Real-time streaming of AI responses
- **Multi-phase Processing**: Research â†’ Analysis â†’ Thinking phases
- **CRM/PMS Integration**: Save research briefs to external systems
- **Beautiful UI**: Modern React interface with Tailwind CSS

## ğŸ“‹ Prerequisites

- Python 3.8+
- Node.js 16+
- npm or yarn
- Groq API Key (required)

## ğŸ› ï¸ Installation

### 1. Clone the repository

```bash
git clone <repository-url>
cd assistant
```

### 2. Set up environment variables

```bash
# Copy the example environment file
cp .env.example .env

# Edit .env and add your Groq API key
# Get your API key from: https://console.groq.com
```

Required environment variable:
- `GROQ_API_KEY`: Your Groq API key for LLM access

### 3. Install dependencies

#### Backend (Python)
```bash
pip install -r requirements.txt
```

#### Frontend (Node.js)
```bash
cd frontend
npm install
cd ..
```

## ğŸš€ Quick Start

### Option 1: Start everything with one command

```bash
./start-all.sh
```

This will:
- Install all dependencies
- Start the backend server on http://localhost:8000
- Start the frontend dev server on http://localhost:8080
- Open API documentation at http://localhost:8000/docs

### Option 2: Start servers separately

#### Terminal 1 - Backend:
```bash
./start-backend.sh
```

#### Terminal 2 - Frontend:
```bash
./start-frontend.sh
```

## ğŸ“ Project Structure

```
/workspace/
â”œâ”€â”€ app/                      # Backend FastAPI application
â”‚   â”œâ”€â”€ main.py              # Main FastAPI app with endpoints
â”‚   â”œâ”€â”€ websocket_handler.py # WebSocket connection manager
â”‚   â”œâ”€â”€ config.py            # Configuration management
â”‚   â”œâ”€â”€ chat_models.py       # Chat data models
â”‚   â”œâ”€â”€ models.py            # Research data models
â”‚   â””â”€â”€ core/                # Core business logic
â”‚       â”œâ”€â”€ chat_engine.py   # Chat processing engine
â”‚       â”œâ”€â”€ memory_manager.py # Memory management with Mem0
â”‚       â”œâ”€â”€ research_engine.py # Research orchestration
â”‚       â”œâ”€â”€ web_research.py  # Web search functionality
â”‚       â””â”€â”€ synthesis.py     # Content synthesis
â”œâ”€â”€ frontend/                 # Frontend React application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/      # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterfaceReal.tsx # Main chat interface
â”‚   â”‚   â”‚   â””â”€â”€ chat/        # Chat-related components
â”‚   â”‚   â”œâ”€â”€ services/        # API services
â”‚   â”‚   â”‚   â””â”€â”€ api.ts       # HTTP and WebSocket clients
â”‚   â”‚   â””â”€â”€ pages/           # Page components
â”‚   â”œâ”€â”€ package.json         # Frontend dependencies
â”‚   â””â”€â”€ vite.config.ts       # Vite configuration
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env.example            # Environment variables template
â””â”€â”€ start-*.sh              # Startup scripts
```

## ğŸ”Œ API Endpoints

### REST API

- `POST /chat/message` - Send a chat message
- `GET /chat/conversations` - List all conversations
- `GET /chat/conversation/{id}` - Get conversation details
- `DELETE /chat/conversation/{id}` - Delete a conversation
- `POST /research/run` - Run research on a query
- `GET /research/brief/{id}` - Get research brief
- `GET /health` - Health check endpoint

### WebSocket

- `ws://localhost:8000/ws/chat/{connection_id}` - WebSocket endpoint

WebSocket message types:
- `chat` - Send chat message
- `research` - Request research
- `list_conversations` - Get conversation list
- `get_history` - Get conversation history
- `ping` - Keep connection alive

## ğŸ”§ Configuration

### Backend Configuration (.env)

```env
# Required
GROQ_API_KEY=your_groq_api_key

# Optional
DEBUG=true
LOG_LEVEL=INFO
CORS_ORIGINS=["http://localhost:8080"]
LLM_MODEL=moonshotai/kimi-k2-instruct
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=4000
```

### Frontend Configuration

Development (`.env.development`):
```env
VITE_API_URL=http://localhost:8000
VITE_WS_URL=ws://localhost:8000
```

Production (`.env.production`):
```env
VITE_API_URL=https://api.yourdomain.com
VITE_WS_URL=wss://api.yourdomain.com
```

## ğŸ§ª Testing the Integration

1. Start both servers using `./start-all.sh`
2. Open http://localhost:8080 in your browser
3. The connection status should show "connected" (green dot)
4. Try sending a message like "What are the latest trends in AI?"
5. Enable research mode for comprehensive analysis
6. Check the browser console for WebSocket messages

## ğŸ› Troubleshooting

### Backend Issues

1. **GROQ_API_KEY not found**
   - Make sure you've created a `.env` file
   - Add your Groq API key: `GROQ_API_KEY=gsk_...`

2. **Port 8000 already in use**
   - Kill the existing process: `lsof -ti:8000 | xargs kill -9`
   - Or change the port in `start-backend.sh`

### Frontend Issues

1. **WebSocket connection failed**
   - Check that the backend is running
   - Verify CORS settings in backend `.env`
   - Check browser console for errors

2. **Port 8080 already in use**
   - Kill the existing process: `lsof -ti:8080 | xargs kill -9`
   - Or change the port in `vite.config.ts`

### Connection Issues

1. **Check backend is running**:
   ```bash
   curl http://localhost:8000/health
   ```

2. **Check WebSocket connection**:
   - Open browser DevTools â†’ Network â†’ WS tab
   - Look for connection to `/ws/chat/`

## ğŸš¢ Deployment

### Backend Deployment

1. Update production environment variables
2. Use a production ASGI server:
   ```bash
   pip install gunicorn
   gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker
   ```

### Frontend Deployment

1. Build for production:
   ```bash
   cd frontend
   npm run build
   ```

2. Serve the `dist` folder with any static file server

### Docker Deployment (Optional)

Create a `Dockerfile` for containerized deployment:

```dockerfile
# Backend
FROM python:3.9
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY app/ ./app/
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

## ğŸ“š Additional Resources

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [React Documentation](https://react.dev/)
- [WebSocket API](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)
- [Groq Console](https://console.groq.com/)

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.